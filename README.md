
# Building a Best Machine Learning Model on Breast Cancer Data

#### Introduction
Breast cancer (BC) is one of the most common cancers among women worldwide, representing the majority of new cancer cases and cancer-related deaths according to global statistics, making it a significant public health problem in today’s society.

The early diagnosis of BC can improve the prognosis and chance of survival significantly, as it can promote timely clinical treatment to patients. Further accurate classification of benign tumors can prevent patients undergoing unnecessary treatments. Thus, the correct diagnosis of BC and classification of patients into malignant or benign groups is the subject of much research. Because of its unique advantages in critical features detection from complex BC datasets, machine learning (ML) is widely recognized as the methodology of choice in BC pattern classification and forecast modelling.

Classification and data mining methods are an effective way to classify data. Especially in medical field, where those methods are widely used in diagnosis and analysis to make decisions.

#### Objective
This analysis aims to observe which features are most helpful in predicting malignant or benign cancer and to see general trends that may aid us in model selection and hyper parameter selection. The goal is to classify whether the breast cancer is benign or malignant. To achieve this i have used machine learning classification methods to fit a function that can predict the discrete class of new input.

#### Machine Learning Model used
We have different types of classification algorithms in Machine Learning :-

 1. Logistic Regression

 2. Nearest Neighbor

 3. Support Vector Machines

 4. Kernel SVM

 5. Naïve Bayes

 6. Decision Tree Algorithm

 7. Random Forest Classification

After applying the different classification models, we have got below accuracies with different models:

1) Logistic Regression — 95.8%

2) Nearest Neighbor — 95.1%

3) Support Vector Machines — 97.2%

4) Kernel SVM — 96.5%

5) Naive Bayes — 91.6%

6) Decision Tree Algorithm — 95.8%

7) Random Forest Classification — 98.6%

So finally we have built our classification model and we can see that Random Forest Classification algorithm gives the best results for our dataset.
